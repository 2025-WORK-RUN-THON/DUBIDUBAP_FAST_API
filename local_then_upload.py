#!/usr/bin/env python3
"""
ë¡œì»¬ì—ì„œ ë¶„ì„ í›„ ì„œë²„ ì—…ë¡œë“œ ì „ëµ
1. ë¡œì»¬ì—ì„œ ì˜¤ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰
2. ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
3. ì„œë²„ì— ë¶„ì„ ê²°ê³¼ë§Œ ì—…ë¡œë“œ
"""

import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, List

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from app.services.audio_processor import audio_processor

async def analyze_locally_then_prepare_upload():
    """ë¡œì»¬ ë¶„ì„ í›„ ì—…ë¡œë“œìš© ë°ì´í„° ì¤€ë¹„"""
    
    # enriched JSON ë¡œë“œ
    enriched_file = Path("data/yt_enriched.json")
    with open(enriched_file, "r", encoding="utf-8") as f:
        videos_data = json.load(f)
    
    # AI ëª¨ë¸ ì´ˆê¸°í™”
    logger.info("ğŸ¤– ë¡œì»¬ AI ëª¨ë¸ ì´ˆê¸°í™”...")
    await audio_processor.initialize_models()
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥ìš©
    analysis_results = []
    
    # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
    for i, video_data in enumerate(videos_data[:3], 1):
        video_id = video_data["id"]
        url = video_data["url"]
        title = video_data["title"]
        
        logger.info(f"ğŸµ ë¡œì»¬ ë¶„ì„ {i}/3: {title}")
        
        # ì‹¤ì œ ì˜¤ë””ì˜¤ ë¶„ì„
        result = await audio_processor.process_youtube_video(url, video_id)
        
        if result["status"] == "completed":
            # ì„œë²„ ì—…ë¡œë“œìš© ë°ì´í„° êµ¬ì¡°
            upload_data = {
                "video_id": video_id,
                "url": url,
                "title": title,
                "view_count": video_data.get("views", 0),
                "tags": video_data.get("tags", []),
                
                # ë¶„ì„ ê²°ê³¼
                "music_summary": {
                    "bpm": result["audio_features"]["bpm"],
                    "key": result["audio_features"]["key"],
                    "mode": result["audio_features"]["mode"],
                    "mode_confidence": result["audio_features"]["mode_confidence"],
                    "pitch_confidence": result["audio_features"]["pitch_confidence"],
                    "duration": result["audio_features"]["duration"],
                    "real_analysis": True
                },
                
                "emotion_analysis": {
                    "dominant_emotion": result["emotion"]["dominant_emotion"],
                    "confidence": result["emotion"]["confidence"],
                    "analysis": result["emotion"]["analysis"],
                    "real_analysis": True
                },
                
                "lyrics_analysis": {
                    "lyrics": result["lyrics"]["text"],
                    "language": result["lyrics"]["language"],
                    "segments": len(result["lyrics"]["segments"]),
                    "confidence": result["lyrics"]["confidence"],
                    "real_analysis": True
                },
                
                "processing_time": result["processing_time"]
            }
            
            analysis_results.append(upload_data)
            logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: BPM {result['audio_features']['bpm']:.1f}")
        
        else:
            logger.warning(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {video_id}")
    
    # ê²°ê³¼ ì €ì¥
    output_file = Path("data/local_analysis_results.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
    logger.info(f"ì´ {len(analysis_results)}ê°œ ë¶„ì„ ì™„ë£Œ")
    
    # ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    create_upload_script(analysis_results)
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    audio_processor.cleanup_temp_files()

def create_upload_script(analysis_results: List[Dict]):
    """ì„œë²„ ì—…ë¡œë“œìš© ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    
    upload_script = f'''#!/usr/bin/env python3
"""
ì„œë²„ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (EC2ì—ì„œ ì‹¤í–‰)
ë¡œì»¬ì—ì„œ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ì„œë²„ DBì— ì €ì¥
"""

import json
import logging
from app.db import get_session, init_db
from app.models import Video, Embedding, AnalysisSummary
from app.services.text_embed import embed_text
from app.services.embeddings import to_bytes
from sqlmodel import select

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def upload_analysis_results():
    """ë¡œì»¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì„œë²„ DBì— ì—…ë¡œë“œ"""
    
    # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
    analysis_data = {json.dumps(analysis_results, ensure_ascii=False, indent=2)}
    
    init_db()
    session = next(get_session())
    
    try:
        for data in analysis_data:
            video_id = data["video_id"]
            title = data["title"]
            
            logger.info(f"ğŸ“¤ ì—…ë¡œë“œ: {{title}}")
            
            # Video ìƒì„±/ì—…ë°ì´íŠ¸
            existing = session.exec(select(Video).where(Video.video_id == video_id)).first()
            
            if existing:
                existing.title = title
                existing.url = data["url"]  
                existing.view_count = data["view_count"]
                video = existing
            else:
                video = Video(
                    video_id=video_id,
                    url=data["url"],
                    title=title,
                    view_count=data["view_count"]
                )
                session.add(video)
            
            session.flush()
            
            # ì„ë² ë”© ìƒì„± (ì„œë²„ì—ì„œ)
            title_embedding = embed_text(title)
            
            tags = data.get("tags", [])
            lyrics_text = f"{{title}} {{' '.join(tags[:5])}}" if tags else title
            lyrics_embedding = embed_text(lyrics_text)
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            session.exec(select(Embedding).where(Embedding.video_id == video.id)).delete()
            session.exec(select(AnalysisSummary).where(AnalysisSummary.video_id == video.id)).delete()
            
            # ìƒˆ ì„ë² ë”© ì¶”ê°€
            embeddings = [
                Embedding(video_id=video.id, kind="title", vector=to_bytes(title_embedding)),
                Embedding(video_id=video.id, kind="lyrics", vector=to_bytes(lyrics_embedding))
            ]
            
            for emb in embeddings:
                session.add(emb)
            
            # ë¶„ì„ ìš”ì•½ ì¶”ê°€
            summaries = [
                AnalysisSummary(video_id=video.id, kind="music_summary", data_json=json.dumps(data["music_summary"])),
                AnalysisSummary(video_id=video.id, kind="audio_emotion", data_json=json.dumps(data["emotion_analysis"])),
                AnalysisSummary(video_id=video.id, kind="lyrics_analysis", data_json=json.dumps(data["lyrics_analysis"]))
            ]
            
            for summary in summaries:
                session.add(summary)
            
            logger.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {{video_id}}")
        
        session.commit()
        logger.info("ğŸ‰ ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {{e}}")
        session.rollback()
        raise
    finally:
        session.close()

if __name__ == "__main__":
    upload_analysis_results()
'''
    
    script_file = Path("upload_to_server.py")
    with open(script_file, "w", encoding="utf-8") as f:
        f.write(upload_script)
    
    logger.info(f"ğŸ“‹ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_file}")

if __name__ == "__main__":
    asyncio.run(analyze_locally_then_prepare_upload())