"""
ì˜ì¡´ì„± ë° ëª¨ë¸ ë¡œë”© ìœ í‹¸ë¦¬í‹°
ëˆ„ë½ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²˜ë¦¬ ë° ìš°ì•„í•œ ëŒ€ì²´ ë°©ì•ˆ ì œê³µ
"""

import logging
import importlib
import sys
from typing import Optional, Dict, Any, Callable
from functools import wraps
import warnings

logger = logging.getLogger(__name__)


class DependencyManager:
    """ì˜ì¡´ì„± ê´€ë¦¬ ë° ëŒ€ì²´ ë°©ì•ˆ ì œê³µ"""
    
    def __init__(self):
        self.available_packages = {}
        self.fallback_strategies = {}
        self._check_core_dependencies()
    
    def _check_core_dependencies(self):
        """í•µì‹¬ ì˜ì¡´ì„± í™•ì¸"""
        core_deps = {
            'torch': 'PyTorch for Hugging Face models',
            'transformers': 'Hugging Face transformers',
            'librosa': 'Audio processing',
            'numpy': 'Numerical computations',
            'sklearn': 'Machine learning utilities'
        }
        
        for package, description in core_deps.items():
            self.available_packages[package] = self._check_package(package)
            if not self.available_packages[package]:
                logger.warning(f"ì„ íƒì  ì˜ì¡´ì„± ëˆ„ë½: {package} ({description})")
    
    def _check_package(self, package_name: str) -> bool:
        """íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            importlib.import_module(package_name)
            return True
        except ImportError:
            return False
    
    def require_package(self, package_name: str, fallback_func: Optional[Callable] = None):
        """íŒ¨í‚¤ì§€ í•„ìˆ˜ ê²€ì¦ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                if not self.available_packages.get(package_name, False):
                    logger.warning(f"íŒ¨í‚¤ì§€ {package_name}ì´(ê°€) ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ì•ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    if fallback_func:
                        return fallback_func(*args, **kwargs)
                    else:
                        raise ImportError(f"í•„ìˆ˜ íŒ¨í‚¤ì§€ {package_name}ì´(ê°€) ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return func(*args, **kwargs)
            return wrapper
        return decorator
    
    def get_safe_import(self, module_name: str, class_name: str = None):
        """ì•ˆì „í•œ import with ëŒ€ì²´ ë°©ì•ˆ"""
        try:
            module = importlib.import_module(module_name)
            if class_name:
                return getattr(module, class_name)
            return module
        except ImportError as e:
            logger.warning(f"ëª¨ë“ˆ import ì‹¤íŒ¨: {module_name} - {e}")
            return None
    
    def install_missing_dependencies(self, packages: list):
        """ëˆ„ë½ëœ ì˜ì¡´ì„± ìë™ ì„¤ì¹˜ ì‹œë„"""
        import subprocess
        
        for package in packages:
            if not self.available_packages.get(package, False):
                try:
                    logger.info(f"íŒ¨í‚¤ì§€ {package} ì„¤ì¹˜ ì‹œë„ ì¤‘...")
                    subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                    self.available_packages[package] = True
                    logger.info(f"íŒ¨í‚¤ì§€ {package} ì„¤ì¹˜ ì™„ë£Œ")
                except subprocess.CalledProcessError as e:
                    logger.error(f"íŒ¨í‚¤ì§€ {package} ì„¤ì¹˜ ì‹¤íŒ¨: {e}")


# ì „ì—­ ì˜ì¡´ì„± ê´€ë¦¬ì
dependency_manager = DependencyManager()


def safe_import_with_fallback(primary_import: str, fallback_func: Callable = None):
    """ì•ˆì „í•œ import with ëŒ€ì²´ í•¨ìˆ˜"""
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            try:
                return await func(*args, **kwargs)
            except ImportError as e:
                logger.warning(f"Import ì˜¤ë¥˜: {e}")
                if fallback_func:
                    logger.info("ëŒ€ì²´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return await fallback_func(*args, **kwargs)
                else:
                    return {'error': f'ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {primary_import}', 'fallback': 'none'}
        
        def sync_wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except ImportError as e:
                logger.warning(f"Import ì˜¤ë¥˜: {e}")
                if fallback_func:
                    logger.info("ëŒ€ì²´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return fallback_func(*args, **kwargs)
                else:
                    return {'error': f'ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {primary_import}', 'fallback': 'none'}
        
        # async í•¨ìˆ˜ì¸ì§€ í™•ì¸
        if hasattr(func, '__code__') and func.__code__.co_flags & 0x80:  # CO_COROUTINE
            return async_wrapper
        else:
            return sync_wrapper
    
    return decorator


def check_gpu_availability() -> Dict[str, Any]:
    """GPU ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
    gpu_info = {
        'cuda_available': False,
        'mps_available': False,  # Apple Silicon
        'device_count': 0,
        'recommended_device': 'cpu'
    }
    
    try:
        import torch
        gpu_info['cuda_available'] = torch.cuda.is_available()
        gpu_info['device_count'] = torch.cuda.device_count() if gpu_info['cuda_available'] else 0
        
        # Apple Silicon MPS ì§€ì› í™•ì¸
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            gpu_info['mps_available'] = True
            gpu_info['recommended_device'] = 'mps'
        elif gpu_info['cuda_available']:
            gpu_info['recommended_device'] = 'cuda'
            
    except ImportError:
        logger.warning("PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ GPU ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return gpu_info


def optimize_model_loading():
    """ëª¨ë¸ ë¡œë”© ìµœì í™” ì„¤ì •"""
    try:
        import torch
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # Warning ì–µì œ (ì„ íƒì )
        warnings.filterwarnings("ignore", category=UserWarning, module="transformers")
        warnings.filterwarnings("ignore", category=FutureWarning, module="transformers")
        
        return True
    except ImportError:
        return False


def get_fallback_emotion_analysis():
    """Hugging Face ëª¨ë¸ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ê°ì • ë¶„ì„"""
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„
    positive_keywords = ['ì‚¬ë‘', 'í–‰ë³µ', 'ê¸°ì¨', 'ì¢‹ì•„', 'ì›ƒìŒ', 'í¬ë§', 'ê¿ˆ', 'í•¨ê»˜', 'ì•„ë¦„ë‹¤ìš´', 'ë”°ëœ»í•œ']
    negative_keywords = ['ìŠ¬í””', 'ì•„í””', 'ëˆˆë¬¼', 'ì´ë³„', 'ì™¸ë¡œìš´', 'ê·¸ë¦¬ì›€', 'í˜ë“¤ì–´', 'ì•„íŒŒ', 'ìŠ¬í”ˆ', 'ì–´ë‘ ']
    
    async def fallback_text_emotion(text: str) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        if not text:
            return {
                'emotions': {'neutral': 1.0},
                'dominant_emotion': 'neutral',
                'confidence': 0.3,
                'korean_emotion': 'ì¤‘ë¦½ì ',
                'method': 'keyword_fallback'
            }
        
        positive_count = sum(1 for keyword in positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in negative_keywords if keyword in text)
        
        total_keywords = positive_count + negative_count
        
        if total_keywords == 0:
            return {
                'emotions': {'neutral': 1.0},
                'dominant_emotion': 'neutral',
                'confidence': 0.3,
                'korean_emotion': 'ì¤‘ë¦½ì ',
                'method': 'keyword_fallback'
            }
        
        positive_ratio = positive_count / total_keywords
        negative_ratio = negative_count / total_keywords
        
        if positive_ratio > negative_ratio:
            dominant = 'positive'
            korean_emotion = 'ê¸ì •ì '
            confidence = min(positive_ratio + 0.3, 0.8)
        elif negative_ratio > positive_ratio:
            dominant = 'negative'
            korean_emotion = 'ë¶€ì •ì '
            confidence = min(negative_ratio + 0.3, 0.8)
        else:
            dominant = 'neutral'
            korean_emotion = 'ì¤‘ë¦½ì '
            confidence = 0.5
        
        emotions = {
            'positive': positive_ratio,
            'negative': negative_ratio,
            'neutral': 1 - (positive_ratio + negative_ratio)
        }
        
        return {
            'emotions': emotions,
            'dominant_emotion': dominant,
            'confidence': confidence,
            'korean_emotion': korean_emotion,
            'method': 'keyword_fallback',
            'keyword_counts': {
                'positive': positive_count,
                'negative': negative_count
            }
        }
    
    return fallback_text_emotion


def install_requirements_on_demand():
    """í•„ìš”ì— ë”°ë¼ requirements ì„¤ì¹˜"""
    
    missing_packages = []
    
    # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
    required_packages = [
        ('transformers', '4.35.0'),
        ('torch', '2.0.0'),
        ('librosa', '0.10.2'),
        ('scikit-learn', '1.3.0')
    ]
    
    for package, min_version in required_packages:
        if not dependency_manager._check_package(package):
            missing_packages.append(f"{package}>={min_version}")
    
    if missing_packages:
        logger.info(f"ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ê°ì§€: {missing_packages}")
        
        install_command = f"pip install {' '.join(missing_packages)}"
        print(f"ğŸ“¦ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëˆ„ë½ëœ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print(f"   {install_command}")
        
        # ìë™ ì„¤ì¹˜ ì‹œë„ (ì„ íƒì )
        response = input("ì§€ê¸ˆ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
        if response == 'y':
            dependency_manager.install_missing_dependencies([p.split('>=')[0] for p in missing_packages])
    
    return len(missing_packages) == 0